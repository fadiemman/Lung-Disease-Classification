{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "166069e3",
   "metadata": {},
   "source": [
    "## Importing useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7db2ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image, ImageStat,ImageOps\n",
    "from skimage.io import imread,imshow,imsave\n",
    "from scipy.stats import entropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import kurtosis,skew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aa978b",
   "metadata": {},
   "source": [
    "## Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b27eaa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'C:/Users/Lenovo/Documents/Study/Master/Seventh Semester/ISM/Programming/Project/ISM/ISM/train'\n",
    "filepath = 'C:/Users/Lenovo/Documents/Study/Master/Seventh Semester/ISM/Programming/Project/ISM/ISM/train.txt'\n",
    "dir_list=os.listdir(train_dir)\n",
    "#dir_list=dir_list[0:1]\n",
    "image_pd=[]\n",
    "rms=[]\n",
    "stddev=[]\n",
    "features=[]\n",
    "kurtVal=[]\n",
    "skewness=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e66dccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findImage(image):\n",
    "    x=[]\n",
    "    image=image.replace('\"','')\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            y = line.split()\n",
    "            x.append(y[0].replace(\"'\",\"\"))\n",
    "            x.append(y[1].replace(\"'\",\"\"))\n",
    "        value = x.index(image)\n",
    "        newvalue=x[value+1]\n",
    "    return newvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "080bf092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that allows to improve the contrast of an image\n",
    "def contrastImage(img):\n",
    "    img = imread(img)\n",
    "    img_to_yuv = cv2.cvtColor(img,cv2.COLOR_BGR2YUV)\n",
    "    img_to_yuv[:,:,0] = cv2.equalizeHist(img_to_yuv[:,:,0])\n",
    "    hist_equalization_result = cv2.cvtColor(img_to_yuv, cv2.COLOR_YUV2BGR)\n",
    "    return hist_equalization_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c749949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in dir_list:\n",
    "    count=count+1;\n",
    "    location = train_dir + \"/\" + i\n",
    "    features.append(findImage(i))\n",
    "    im = Image.open(location) #Using PIL\n",
    "    im2 = ImageOps.grayscale(im) #Change to Grayscale\n",
    "    im_gray = ImageOps.grayscale(im)\n",
    "    #im_gray = contrastImage(im_gray)\n",
    "    image_pd.append(i)\n",
    "    stat = ImageStat.Stat(im2)\n",
    "     # KURTOSIS and SKEWNESS\n",
    "    print(\"Kurtosis: \", kurtosis(im_gray, axis=None) )\n",
    "    kurtVal.append(kurtosis(im_gray, axis=None))\n",
    "    \n",
    "    print(\"Skew: \", skew(im_gray, axis=None))\n",
    "    skewness.append(skew(im_gray, axis=None))\n",
    "    \n",
    "    #Root Mean Square and Standard Deviation\n",
    "    rms.append(stat.rms[0])\n",
    "    stddev.append(stat.stddev[0])\n",
    "    print(i,\" \",count)\n",
    "df = pd.DataFrame({'image': image_pd, 'rms': rms,'stddev':stddev,'features':features, 'Kurtosis' : kurtVal, 'Skewness': skewness})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a9768",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 7)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ced7b4",
   "metadata": {},
   "source": [
    "## Computing the entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db84be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a pattern directory to access all images\n",
    "im_locations = []\n",
    "for im in image_pd:\n",
    "    im = train_dir +'/'+ im\n",
    "    im_locations.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72946c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing entropy for all images in the train dataset\n",
    "probs = []\n",
    "counts = []\n",
    "entropy_cal = []\n",
    "for i in range (len(im_locations)):\n",
    "    counts.append(np.unique(imread(im_locations[i],as_gray=True), return_counts= True))\n",
    "    sum_counts = sum(counts[i][1])\n",
    "    for number in counts[i][1]:\n",
    "        probs.append(number/sum_counts)\n",
    "    entropy_cal.append(entropy(np.array(probs)))\n",
    "    probs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the entropy to the dataframe\n",
    "df = df.assign(entropy=entropy_cal)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d9ae79",
   "metadata": {},
   "source": [
    "## Creating models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e62a04",
   "metadata": {},
   "source": [
    "### Test 1 : Using only the root mean square as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b172f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is the root mean squares of all training images and Y is the labels associated to those images\n",
    "X = df.rms\n",
    "Y = df.features\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40517091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting X and Y into training and validation dataset. Applying a shuffle to the data and stratify helps to keep the same proportions of each labe\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X,Y, shuffle = True, stratify= Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c1f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping X to use it as input to the model\n",
    "X_train = X_train.values.reshape(-1,1)\n",
    "X_val = X_val.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be360c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an SVM named model1 and fitting it with the training set\n",
    "model1 = svm.SVC()\n",
    "model1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca02e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the labels of the validation set\n",
    "y_pred = model1.predict(X_val)\n",
    "y_pred\n",
    "np.unique(y_pred) #Checking which cases does the prediction include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219f5fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing the accuracy score using the predicted labels and comparing them to the real ones\n",
    "accuracy_score(Y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating another model using KNN with k = 3 . K has been randomly chosen and can be changed of course\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k = 3\n",
    "clf = KNeighborsClassifier(n_neighbors = k)\n",
    "clf.fit(X_train, Y_train)\n",
    "Ypred_v = clf.predict(X_val)\n",
    "accuracy_score(Y_val, Ypred_v)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14794a94",
   "metadata": {},
   "source": [
    "#Creating a third model using SVM but with a linear kernel to see if there are any relevant changes to the accuracy\n",
    "model3 = svm.SVC(kernel='linear')\n",
    "model3.fit(X_train, Y_train)\n",
    "y_pred3 = model3.predict(X_val)\n",
    "accuracy_score(y_pred3, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c63aa4",
   "metadata": {},
   "source": [
    "### Test 2 : Using Kurtosis and Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59696d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X contains the kurtosis and skewness of all images\n",
    "X2 = df[['Kurtosis','Skewness']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9231e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_val, Y2_train, Y2_val = train_test_split(X2,Y, shuffle =True, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5f6d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data. StandardScaler uses the mean and std of the data which are computed automatically in the fit part.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=True, with_std=True)\n",
    "sc = sc.fit(X2_train)\n",
    "# Transforming training and validation set into normalized values\n",
    "X2train_n = sc.transform(X2_train)\n",
    "X2val_n = sc.transform(X2_val)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5cd5993f",
   "metadata": {},
   "source": [
    "# Creating an SVM with fit and predict functions \n",
    "model4 = svm.SVC(kernel = 'poly')\n",
    "model4.fit(X2train_n, Y2_train)\n",
    "y2_pred = model4.predict(X2val_n)\n",
    "accuracy_score(y2_pred, Y2_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4e863",
   "metadata": {},
   "source": [
    "### Test 3 : Using rms, Stddev , Kurtosis, Skewness and entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ac306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = df[['rms','stddev','Kurtosis','Skewness','entropy']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6769b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train, X3_val, Y3_train, Y3_val = train_test_split(X3,Y, shuffle =True, stratify = Y)\n",
    "X3_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37689abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=True, with_std=True)\n",
    "sc = sc.fit(X3_train)\n",
    "X3train_n = sc.transform(X3_train)\n",
    "X3val_n = sc.transform(X3_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44257a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = svm.SVC()\n",
    "model7.fit(X3train_n, Y3_train)\n",
    "y3_pred = model7.predict(X3val_n)\n",
    "accuracy_score(y3_pred, Y3_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea342c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y3_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c76e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y3_pred, Y3_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c9dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a decision tree model\n",
    "from sklearn import tree\n",
    "model_tree = tree.DecisionTreeClassifier()\n",
    "model_tree.fit(X3train_n, Y3_train)\n",
    "y3_tree = model_tree.predict(X3val_n)\n",
    "accuracy_score(y3_tree, Y3_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e1a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing another kernel for SVM\n",
    "model8 = svm.SVC(kernel = 'poly')\n",
    "model8.fit(X3train_n, Y3_train)\n",
    "y4_pred = model8.predict(X3val_n)\n",
    "accuracy_score(y4_pred, Y3_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9219f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing a KNN model\n",
    "k = 75\n",
    "clf = KNeighborsClassifier(n_neighbors = k)\n",
    "clf.fit(X3train_n, Y3_train)\n",
    "Ypred_v = clf.predict(X3val_n)\n",
    "accuracy_score(Y3_val, Ypred_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84684bc3",
   "metadata": {},
   "source": [
    "## Testing the contrastImage function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c2a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "location\n",
    "imshow(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f162e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_read = contrastImage(location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0ec49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(im_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605302df",
   "metadata": {},
   "source": [
    "## Creating text file for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca6c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textfile_predictions(image_set,prediction_set,textfile_name):\n",
    "    f= open(textfile_name,\"w+\")\n",
    "    for i in range (len(image_set)):\n",
    "        f.write(image_set[i]+\" \")\n",
    "        f.write(prediction_set[i]+\"\\n\")\n",
    "    f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636d16b3",
   "metadata": {},
   "source": [
    "## Computing the hu moments as well as other features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b79e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_hu_moments(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
    "    return feature\n",
    "\n",
    "def fd_haralick(image):    # convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # compute the haralick texture feature vector\n",
    "    haralick = mahotas.features.haralick(gray).mean(axis=0)\n",
    "    return haralick\n",
    " \n",
    "def fd_histogram(image, mask=None):\n",
    "    # convert the image to HSV color-space\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # compute the color histogram\n",
    "    hist  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
    "    # normalize the histogram\n",
    "    cv2.normalize(hist, hist)\n",
    "    hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16872c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the hu moments for all images\n",
    "hu_moments = []\n",
    "for im in im_locations :\n",
    "    hu_moments.append(fd_hu_moments(imread(im)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6abd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding hu moments to the dataframe\n",
    "df['hu moments'] = hu_moments\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d86ed42",
   "metadata": {},
   "source": [
    "### test 4 : Using hu moments (in progress...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dcc6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = df['hu moments']\n",
    "for i in range(len(X4)):\n",
    "    X4[i] = X4[i][0:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33dec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X4.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9875f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "X4_train, X4_val, Y4_train, Y4_val = train_test_split(X4,Y, shuffle =True, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8ef72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = svm.SVC()\n",
    "model8.fit(X4_train.values, Y4_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4475c66",
   "metadata": {},
   "source": [
    "### Working on test data : Prediction number 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f695109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_testlist = []\n",
    "test_dir = 'data/test'\n",
    "test_noise_dir = 'data/test_noise'\n",
    "dir_testlist=os.listdir(test_dir)\n",
    "len(dir_testlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140cc571",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagetest_pd = []\n",
    "rms_test=[]\n",
    "stddev_test=[]\n",
    "kurtVal_test=[]\n",
    "skewness_test=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf8f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in dir_testlist:\n",
    "    count=count+1;\n",
    "    location = test_dir + \"/\" + i\n",
    "    im = Image.open(location) #Using PIL\n",
    "    im2 = ImageOps.grayscale(im) #Change to Grayscale\n",
    "    im_gray = ImageOps.grayscale(im)\n",
    "    #im_gray = contrastImage(im_gray)\n",
    "    imagetest_pd.append(i)\n",
    "    stat = ImageStat.Stat(im2)\n",
    "     # KURTOSIS and SKEWNESS\n",
    "    print(\"Kurtosis: \", kurtosis(im_gray, axis=None) )\n",
    "    kurtVal_test.append(kurtosis(im_gray, axis=None))\n",
    "    \n",
    "    print(\"Skew: \", skew(im_gray, axis=None))\n",
    "    skewness_test.append(skew(im_gray, axis=None))\n",
    "    \n",
    "    #Root Mean Square and Standard Deviation\n",
    "    rms_test.append(stat.rms[0])\n",
    "    stddev_test.append(stat.stddev[0])\n",
    "    print(i,\" \",count)\n",
    "df_test = pd.DataFrame({'image': imagetest_pd, 'rms': rms_test,'stddev':stddev_test, 'Kurtosis' : kurtVal_test, 'Skewness': skewness_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12613a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb4ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_testlocations = []\n",
    "for im in imagetest_pd:\n",
    "    im = test_dir +'/'+ im\n",
    "    im_testlocations.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b615fa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing entropy for all images in the test dataset\n",
    "probs = []\n",
    "counts = []\n",
    "entropy_cal = []\n",
    "for i in range (len(im_testlocations)):\n",
    "    counts.append(np.unique(imread(im_testlocations[i],as_gray=True), return_counts= True))\n",
    "    sum_counts = sum(counts[i][1])\n",
    "    for number in counts[i][1]:\n",
    "        probs.append(number/sum_counts)\n",
    "    entropy_cal.append(entropy(np.array(probs)))\n",
    "    probs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f050748",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.assign(entropy=entropy_cal)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6bd2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all the features for the test dataset\n",
    "X3_test = df_test[['rms','stddev','Kurtosis','Skewness','entropy']]\n",
    "X3_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b2aed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test dataset using the best model yet (64% accuracy)\n",
    "X3test_n = sc.transform(X3_test)\n",
    "ytest_pred = model7.predict(X3test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7052ca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a textfile containing the images and the associated classes\n",
    "textfile_predictions(imagetest_pd,ytest_pred,'test_predictions_version1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8decf16",
   "metadata": {},
   "source": [
    "### Working on noise test data : Prediction number 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b940b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_noisetestlist = []\n",
    "dir_noisetestlist=os.listdir(test_noise_dir)\n",
    "len(dir_noisetestlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880b1f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenoisetest_pd = []\n",
    "rms_noisetest=[]\n",
    "stddev_noisetest=[]\n",
    "kurtVal_noisetest=[]\n",
    "skewness_noisetest=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in dir_noisetestlist:\n",
    "    count=count+1;\n",
    "    location = test_noise_dir + \"/\" + i\n",
    "    im = Image.open(location) #Using PIL\n",
    "    im2 = ImageOps.grayscale(im) #Change to Grayscale\n",
    "    im_gray = ImageOps.grayscale(im)\n",
    "    #im_gray = contrastImage(im_gray)\n",
    "    imagenoisetest_pd.append(i)\n",
    "    stat = ImageStat.Stat(im2)\n",
    "     # KURTOSIS and SKEWNESS\n",
    "    print(\"Kurtosis: \", kurtosis(im_gray, axis=None) )\n",
    "    kurtVal_noisetest.append(kurtosis(im_gray, axis=None))\n",
    "    \n",
    "    print(\"Skew: \", skew(im_gray, axis=None))\n",
    "    skewness_noisetest.append(skew(im_gray, axis=None))\n",
    "    \n",
    "    #Root Mean Square and Standard Deviation\n",
    "    rms_noisetest.append(stat.rms[0])\n",
    "    stddev_noisetest.append(stat.stddev[0])\n",
    "    print(i,\" \",count)\n",
    "df_noisetest = pd.DataFrame({'image': imagenoisetest_pd, 'rms': rms_noisetest,'stddev':stddev_noisetest, 'Kurtosis' : kurtVal_noisetest, 'Skewness': skewness_noisetest})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e042f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noisetest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f9df91",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_noisetestlocations = []\n",
    "for im in imagenoisetest_pd:\n",
    "    im = test_noise_dir +'/'+ im\n",
    "    im_noisetestlocations.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5173ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = []\n",
    "counts = []\n",
    "entropy_cal = []\n",
    "for i in range (len(im_noisetestlocations)):\n",
    "    counts.append(np.unique(imread(im_noisetestlocations[i],as_gray=True), return_counts= True))\n",
    "    sum_counts = sum(counts[i][1])\n",
    "    for number in counts[i][1]:\n",
    "        probs.append(number/sum_counts)\n",
    "    entropy_cal.append(entropy(np.array(probs)))\n",
    "    probs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a6588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noisetest = df_noisetest.assign(entropy=entropy_cal)\n",
    "df_noisetest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_noisetest = df_noisetest[['rms','stddev','Kurtosis','Skewness','entropy']]\n",
    "X3_noisetest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdfbc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3noisetest_n = sc.transform(X3_noisetest)\n",
    "ynoisetest_pred = model7.predict(X3noisetest_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ee08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile_predictions(imagenoisetest_pd,ynoisetest_pred,'noisetest_predictions_version1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e0e45b",
   "metadata": {},
   "source": [
    "### More features : LocalBinaryPatterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15226e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalBinaryPatterns:\n",
    "\tdef __init__(self, numPoints, radius):\n",
    "\t\t# store the number of points and radius\n",
    "\t\tself.numPoints = numPoints\n",
    "\t\tself.radius = radius\n",
    "\tdef describe(self, image, eps=1e-7):\n",
    "\t\t# compute the Local Binary Pattern representation\n",
    "\t\t# of the image, and then use the LBP representation\n",
    "\t\t# to build the histogram of patterns\n",
    "\t\tlbp = feature.local_binary_pattern(image, self.numPoints,\n",
    "\t\t\tself.radius, method=\"uniform\")\n",
    "\t\t(hist, _) = np.histogram(lbp.ravel(),\n",
    "\t\t\tbins=np.arange(0, self.numPoints + 3),\n",
    "\t\t\trange=(0, self.numPoints + 2))\n",
    "\t\t# normalize the histogram\n",
    "\t\thist = hist.astype(\"float\")\n",
    "\t\thist /= (hist.sum() + eps)\n",
    "\t\t# return the histogram of Local Binary Patterns\n",
    "\t\treturn hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a5de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = LocalBinaryPatterns(24, 8)\n",
    "desc2 = LocalBinaryPatterns(16, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3ce3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[]\n",
    "# loop over the training images\n",
    "for imagePath in im_locations:\n",
    "\t# load the image, convert it to grayscale, and describe it\n",
    "\timage = cv2.imread(imagePath)\n",
    "\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\thist = desc.describe(gray)\n",
    "\t# extract the label from the image path, then update the\n",
    "\t# label and data lists\n",
    "\tdata.append(hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5638f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 =[]\n",
    "# loop over the training images\n",
    "for imagePath in im_locations:\n",
    "\t# load the image, convert it to grayscale, and describe it\n",
    "\timage = cv2.imread(imagePath)\n",
    "\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\thist = desc2.describe(gray)\n",
    "\t# extract the label from the image path, then update the\n",
    "\t# label and data lists\n",
    "\tdata2.append(hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00cb6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(data,Y, shuffle = True, stratify= Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda3d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9fb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(X_train, Y_train)\n",
    "y3_pred = model.predict(X_val)\n",
    "accuracy_score(y3_pred, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29cb120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=True, with_std=True)\n",
    "sc = sc.fit(X_train)\n",
    "# Transforming training and validation set into normalized values\n",
    "Xtrain_n = sc.transform(X_train)\n",
    "Xval_n = sc.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f555db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = svm.SVC()\n",
    "model2.fit(Xtrain_n, Y_train)\n",
    "y3_pred = model2.predict(Xval_n)\n",
    "accuracy_score(y3_pred, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aed6366",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data.copy()\n",
    "data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6abce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k = 55\n",
    "clf = KNeighborsClassifier(n_neighbors = k)\n",
    "clf.fit(Xtrain_n, Y_train)\n",
    "Ypred_v = clf.predict(Xval_n)\n",
    "accuracy_score(Y_val, Ypred_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d4232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce0cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = np.hstack((data_copy,data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4892cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1f0bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_val, Y2_train, Y2_val = train_test_split(data_copy,Y, shuffle = True, stratify= Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6695f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = svm.SVC()\n",
    "model3.fit(X2_train, Y2_train)\n",
    "y3_pred = model3.predict(X2_val)\n",
    "accuracy_score(y3_pred, Y2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e8cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler(with_mean=True, with_std=True)\n",
    "sc = sc.fit(X2_train)\n",
    "# Transforming training and validation set into normalized values\n",
    "X2train_n = sc.transform(X2_train)\n",
    "X2val_n = sc.transform(X2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab2808",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = svm.SVC()\n",
    "model4.fit(X2train_n, Y2_train)\n",
    "y3_pred = model4.predict(X2val_n)\n",
    "accuracy_score(y3_pred, Y2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751cd6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc439242",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y3_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b235a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y3_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f310c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d893cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y3_pred, Y2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d79d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(Y2_val, y3_pred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "model_tree = tree.DecisionTreeClassifier()\n",
    "model_tree.fit(X2train_n, Y2_train)\n",
    "y2_tree = model_tree.predict(X2val_n)\n",
    "accuracy_score(y2_tree, Y2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdae887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "model_forest = RandomForestClassifier()\n",
    "model_forest.fit(X2train_n, Y2_train)\n",
    "y2_forest = model_forest.predict(X2val_n)\n",
    "accuracy_score(y2_forest, Y2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe15152",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trees = ExtraTreesClassifier()\n",
    "model_trees.fit(X2train_n, Y2_train)\n",
    "y2_trees = model_trees.predict(X2val_n)\n",
    "accuracy_score(y2_trees, Y2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4469b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k = 24\n",
    "clf = KNeighborsClassifier(n_neighbors = k)\n",
    "clf.fit(X2train_n, Y2_train)\n",
    "Ypred_v = clf.predict(X2val_n)\n",
    "accuracy_score(Y2_val, Ypred_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e583af4f",
   "metadata": {},
   "source": [
    "### Calculating LocalBinaryPatterns on test data and test data with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be34a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatest =[]\n",
    "datatest2 = []\n",
    "# loop over the training images\n",
    "for imagePath in im_testlocations:\n",
    "\t# load the image, convert it to grayscale, and describe it\n",
    "\timage = cv2.imread(imagePath)\n",
    "\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\thist = desc.describe(gray)\n",
    "\thist2 = desc2.describe(gray)\n",
    "\t# extract the label from the image path, then update the\n",
    "\t# label and data lists\n",
    "\tdatatest.append(hist)\n",
    "\tdatatest2.append(hist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c86b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datanoisetest =[]\n",
    "datanoisetest2 = []\n",
    "# loop over the training images\n",
    "for imagePath in im_noisetestlocations:\n",
    "\t# load the image, convert it to grayscale, and describe it\n",
    "\timage = cv2.imread(imagePath)\n",
    "\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\thist = desc.describe(gray)\n",
    "\thist2 = desc2.describe(gray)\n",
    "\t# extract the label from the image path, then update the\n",
    "\t# label and data lists\n",
    "\tdatanoisetest.append(hist)\n",
    "\tdatanoisetest2.append(hist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380eafe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatest3 = np.hstack((datatest,datatest2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d6e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatest3_n = sc.transform(datatest3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9887a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3test_svm = model4.predict(datatest3_n)\n",
    "np.unique(y3test_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6266da",
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile_predictions(imagetest_pd,y3test_svm,'test_predictions_version2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ab62c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datanoisetest3 = np.hstack((datanoisetest,datanoisetest2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f365b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datanoisetest3_n = sc.transform(datanoisetest3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f106e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3noisetest_svm = model4.predict(datanoisetest3_n)\n",
    "np.unique(y3noisetest_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6254ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile_predictions(imagenoisetest_pd,y3noisetest_svm,'noisetest_predictions_version2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa406fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2test_forest = model_forest.predict(datatest3_n)\n",
    "np.unique(y2test_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b137a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile_predictions(imagetest_pd,y2test_forest,'test_predictions_version3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136eab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2noisetest_forest = model_forest.predict(datanoisetest3_n)\n",
    "np.unique(y2noisetest_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a5c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile_predictions(imagenoisetest_pd,y2noisetest_forest,'noisetest_predictions_version3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1386d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2test_trees = model_trees.predict(datatest3_n)\n",
    "np.unique(y2test_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f932aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile_predictions(imagetest_pd,y2test_trees,'test_predictions_version4.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea7cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2noisetest_trees = model_trees.predict(datanoisetest3_n)\n",
    "np.unique(y2noisetest_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ea8e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile_predictions(imagenoisetest_pd,y2noisetest_trees,'noisetest_predictions_version4.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f083b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytestpred_v = clf.predict(datatest3_n)\n",
    "np.unique(Ytestpred_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aefa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile_predictions(imagetest_pd,Ytestpred_v,'test_predictions_version5.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b644835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ynoisetestpred_v = clf.predict(datanoisetest3_n)\n",
    "np.unique(Ynoisetestpred_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669d0035",
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile_predictions(imagenoisetest_pd,Ynoisetestpred_v,'noisetest_predictions_version5.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c09659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
